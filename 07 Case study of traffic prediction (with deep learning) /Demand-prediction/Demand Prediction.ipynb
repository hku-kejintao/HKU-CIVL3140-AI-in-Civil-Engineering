{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f36c1a31",
   "metadata": {},
   "source": [
    "# Case Study of Traffic Prediction (Demand Prediction)\n",
    "## Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3fcbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def compute_metric(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true[np.where(y_true > 5)[0]], y_pred[np.where(y_true > 5)[0]])\n",
    "    return mae, rmse, mape\n",
    "  \n",
    "def get_dataloader(X, y, device, bs, shuffle):\n",
    "    return torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.FloatTensor(X).to(device), \n",
    "                    torch.FloatTensor(y).to(device)), batch_size=bs, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "def calculate_metric_torch(true, pred, mask_value=5):\n",
    "    mae = torch.mean(torch.abs(true - pred))\n",
    "    rmse = torch.sqrt(torch.mean((pred - true) ** 2))\n",
    "    if mask_value != None:\n",
    "        mask = torch.gt(true, mask_value)\n",
    "        pred = torch.masked_select(pred, mask)\n",
    "        true = torch.masked_select(true, mask)\n",
    "    mape = torch.mean(torch.abs(torch.div((true - pred), true)))\n",
    "    return mae, rmse, mape\n",
    "\n",
    "def trainer(model, lr, epochs, train_loader, val_loader, test_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    MSE = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = list()\n",
    "        for src, trg in train_loader:\n",
    "            pred = model(src)\n",
    "            loss = MSE(pred, trg)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            epoch_loss.append(loss.item())\n",
    "        epoch_loss = np.mean(epoch_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        best_rmse = epoch_loss\n",
    "        with torch.no_grad():\n",
    "            preds, trues = list(), list()\n",
    "            for src, trg in val_loader:\n",
    "                pred = model(src)\n",
    "                preds.append(pred)\n",
    "                trues.append(trg)\n",
    "            mae, rmse, mape = calculate_metric_torch(torch.cat(trues), torch.cat(preds))\n",
    "\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                preds, trues = list(), list()\n",
    "                for src, trg in test_loader:\n",
    "                    pred = model(src)\n",
    "                    preds.append(pred)\n",
    "                    trues.append(trg)\n",
    "                test_mae, test_rmse, test_mape = calculate_metric_torch(torch.cat(trues), torch.cat(preds))\n",
    "        \n",
    "        print('Epoch %d, training loss: %.3f, validation mae: %.3f, rmse: %.3f, mape: %.3f' % (epoch, epoch_loss, mae, rmse, mape))\n",
    "    \n",
    "    return test_mae, test_rmse, test_mape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d39cd5f",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e71a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = np.load('./processed_demand_datasetsMAN.npz')\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = datasets['trainX'], datasets['valX'], datasets['testX'], datasets['trainy'], datasets['valy'], datasets['testy']\n",
    "\n",
    "\n",
    "num_nodes = X_train.shape[0]\n",
    "edges = np.load('./edges_GAman.npy')\n",
    "\n",
    "adj = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "for i in range(num_nodes): \n",
    "    adj[i,i] = 1\n",
    "    \n",
    "for i in range(len(edges)):\n",
    "    adj[edges[i,0], edges[i,1]] = 1\n",
    "    \n",
    "adj = torch.LongTensor(adj)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c5dc979",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb05e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mae: 2.164, rmse: 4.394, mape: 21.693\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=1000)\n",
    "rf.fit(X_train.reshape(-1,42), y_train.reshape(-1))\n",
    "\n",
    "pred = rf.predict(X_test.reshape(-1,42))\n",
    "mae, rmse, mape = compute_metric(y_test.reshape(-1), pred)\n",
    "errors_rf = pd.DataFrame({'MAE': mae, 'RMSE': rmse, 'MAPE': mape}, index=['RF'])\n",
    "\n",
    "print('test mae: %.3f, rmse: %.3f, mape: %.3f' % (mae, rmse, mape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1427b2a7",
   "metadata": {},
   "source": [
    "## GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19ccb09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mae: 2.224, rmse: 4.432, mape: 22.182\n"
     ]
    }
   ],
   "source": [
    "gbdt = GradientBoostingRegressor(random_state=1000)\n",
    "gbdt.fit(X_train.reshape(-1,42), y_train.reshape(-1))\n",
    "\n",
    "pred = gbdt.predict(X_test.reshape(-1,42))\n",
    "mae, rmse, mape = compute_metric(y_test.reshape(-1), pred)\n",
    "errors_gbdt = pd.DataFrame({'MAE': mae, 'RMSE': rmse, 'MAPE': mape}, index=['GBDT'])\n",
    "\n",
    "print('test mae: %.3f, rmse: %.3f, mape: %.3f' % (mae, rmse, mape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bef049d",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61100aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mae: 2.273, rmse: 4.587, mape: 23.100\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(random_state=200, max_iter=400)\n",
    "mlp.fit(X_train.reshape(-1,42), y_train.reshape(-1))\n",
    "\n",
    "pred = mlp.predict(X_test.reshape(-1,42))\n",
    "mae, rmse, mape = compute_metric(y_test.reshape(-1), pred)\n",
    "errors_mlp = pd.DataFrame({'MAE': mae, 'RMSE': rmse, 'MAPE': mape}, index=['MLP'])\n",
    "\n",
    "print('test mae: %.3f, rmse: %.3f, mape: %.3f' % (mae, rmse, mape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58252853",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74edb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, hidden_dim1, num_layers, hidden_dim2):\n",
    "        super().__init__()\n",
    "        self.GRU = nn.GRU(1, hidden_dim1, num_layers, batch_first=True)\n",
    "        self.Dense = nn.Sequential(nn.Linear(hidden_dim1, hidden_dim2), nn.ReLU(), nn.Linear(hidden_dim2, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        o, h = self.GRU(x)\n",
    "        x = self.Dense(h[-1])\n",
    "        return x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fe72db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 136.957, validation mae: 3.005, rmse: 6.478, mape: 0.303\n",
      "Epoch 1, training loss: 26.717, validation mae: 2.838, rmse: 6.337, mape: 0.284\n",
      "Epoch 2, training loss: 25.051, validation mae: 3.144, rmse: 6.422, mape: 0.315\n",
      "test mae: 2.526, rmse: 4.655, mape: 0.252\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_dataloader(X_train.reshape(-1,42,1), y_train.reshape(-1), device, 64, True)\n",
    "val_loader = get_dataloader(X_val.reshape(-1,42,1), y_val.reshape(-1), device, y_test.reshape(-1).shape[0], True)\n",
    "test_loader = get_dataloader(X_test.reshape(-1,42,1), y_test.reshape(-1), device, y_test.reshape(-1).shape[0], False)\n",
    "\n",
    "#####################################################################################################################\n",
    "# After class, you can try different learning rates and training epochs yourself. \n",
    "# Here for quick results, we just set the training epoch to 3.\n",
    "lr = 0.001\n",
    "epochs = 3\n",
    "# For the sake of simplicity, we also omitted the parameter tuning process here. \n",
    "# The correct way is to adjust on the validation set to get the best hyperparameters, and then evaluate the model based on the test set.\n",
    "#####################################################################################################################\n",
    "\n",
    "model = GRU(64, 2, 32).to(device)\n",
    "\n",
    "mae, rmse, mape = trainer(model, lr, epochs, train_loader, val_loader, test_loader)\n",
    "errors_gru = pd.DataFrame({'MAE': mae.item(), 'RMSE': rmse.item(), 'MAPE': mape.item()}, index=['GRU'])\n",
    "\n",
    "print('test mae: %.3f, rmse: %.3f, mape: %.3f' % (mae.item(), rmse.item(), mape.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2aa1e5c7",
   "metadata": {},
   "source": [
    "## GRU-GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, device, in_dim, out_dim, alpha=0.2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.alpha = alpha\n",
    "        self.dropout = dropout\n",
    "        self.weights = nn.Parameter(torch.FloatTensor(in_dim, out_dim))\n",
    "        nn.init.xavier_normal_(self.weights.data, gain=1.414)\n",
    "        self.a = nn.Parameter(torch.FloatTensor(2*out_dim, 1))\n",
    "        nn.init.xavier_normal_(self.a.data, gain=1.414)\n",
    "\n",
    "    def forward(self, h, adj):\n",
    "        \"\"\"\n",
    "        h: (bs, num_node, in_dim)\n",
    "        adj: (num_node, num_node)\n",
    "        return (bs, num_node, out_dim)\n",
    "        \"\"\"\n",
    "        bs, num_node, in_dim = h.size()\n",
    "        src, trg = torch.nonzero(adj.long(), as_tuple=True)\n",
    "        \n",
    "        Wh = torch.matmul(h, self.weights) # (bs, num_node, out_dim)\n",
    "        edge_h = torch.cat([Wh[:,src,:], Wh[:,trg,:]], dim=-1) # (bs, num_edges, 2*out_dim)\n",
    "        edge_e = F.leaky_relu(torch.matmul(edge_h, self.a), negative_slope=self.alpha).squeeze(-1) # (bs, num_edges)\n",
    "\n",
    "        attention = -9e15*torch.ones(bs, num_node, num_node).to(self.device) #（bs, num_node, num_node)\n",
    "        attention[:, src, trg] = edge_e\n",
    "        attention = F.dropout(F.softmax(attention, dim=-1), self.dropout) #（bs, num_node, num_node)\n",
    "\n",
    "        h_prime = torch.einsum('bij,bjo->bio', attention, Wh)\n",
    "\n",
    "        return h_prime\n",
    "    \n",
    "    \n",
    "class GRUGAT(nn.Module):\n",
    "    def __init__(self, device, in_dim, out_dim, num_node, adj):\n",
    "        super().__init__()\n",
    "        self.adj = adj\n",
    "        self.gru = nn.GRU(1, in_dim, 2, batch_first=True)\n",
    "        self.gat = GATLayer(device, in_dim, out_dim)\n",
    "        self.end_conv = nn.Conv1d(out_dim, 1, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (bs, num_node, time_step)\n",
    "        X = []\n",
    "        for i in range(x.size(1)):\n",
    "            o, h = self.gru(x[:,i,:].unsqueeze(-1))\n",
    "            X.append(h[-1])\n",
    "        X = torch.stack(X)\n",
    "        X = self.gat(X.permute(1,0,2), self.adj) # (bs, num_node, 16)\n",
    "        X = self.end_conv(X.permute(0,2,1))\n",
    "        return X.squeeze(1)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a769b89d",
   "metadata": {},
   "source": [
    "For a complex model, such as the hybrid model of GAT and GRU used here, the training time is longer due to the larger number of parameters involved. The hyperparameter tuning process of complex models is usually more complicated, and some training tricks need to be involved, such as learning rate decay and early stopping mechanism. \\\n",
    "Here, also for simplicity and quick display of results, we only set the training epoch to 3 and set the learning rate to a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f415df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 688.228, validation mae: 14.236, rmse: 22.770, mape: 0.618\n",
      "Epoch 1, training loss: 612.897, validation mae: 12.425, rmse: 19.892, mape: 0.761\n",
      "Epoch 2, training loss: 479.127, validation mae: 10.646, rmse: 19.284, mape: 0.652\n",
      "test mae: 10.500, rmse: 19.010, mape: 0.645\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_dataloader(X_train.transpose(1,0,2), y_train.T, device, 36, True)\n",
    "val_loader = get_dataloader(X_val.transpose(1,0,2), y_val.T, device, 72, False)\n",
    "test_loader = get_dataloader(X_test.transpose(1,0,2), y_test.T, device, 72, False)\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 3\n",
    "\n",
    "model = GRUGAT(device, 10, 128, 198, adj).to(device)\n",
    "\n",
    "mae, rmse, mape = trainer(model, lr, epochs, train_loader, val_loader, test_loader)\n",
    "errors_grugat = pd.DataFrame({'MAE': mae.item(), 'RMSE': rmse.item(), 'MAPE': mape.item()}, index=['GRU-GAT'])\n",
    "print('test mae: %.3f, rmse: %.3f, mape: %.3f' % (mae.item(), rmse.item(), mape.item()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee76fcea",
   "metadata": {},
   "source": [
    "## Error comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2512d956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>2.163976</td>\n",
       "      <td>4.393530</td>\n",
       "      <td>21.693186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBDT</th>\n",
       "      <td>2.223783</td>\n",
       "      <td>4.431532</td>\n",
       "      <td>22.182326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>2.273329</td>\n",
       "      <td>4.587292</td>\n",
       "      <td>23.100089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>2.525941</td>\n",
       "      <td>4.655260</td>\n",
       "      <td>0.252132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU-GAT</th>\n",
       "      <td>10.500470</td>\n",
       "      <td>19.010136</td>\n",
       "      <td>0.645191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE       RMSE       MAPE\n",
       "RF        2.163976   4.393530  21.693186\n",
       "GBDT      2.223783   4.431532  22.182326\n",
       "MLP       2.273329   4.587292  23.100089\n",
       "GRU       2.525941   4.655260   0.252132\n",
       "GRU-GAT  10.500470  19.010136   0.645191"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = pd.concat([errors_rf, errors_gbdt, errors_mlp, errors_gru, errors_grugat])\n",
    "errors\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bdd6def",
   "metadata": {},
   "source": [
    "## Use Colab to reproduce the above code on the cloud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24718656",
   "metadata": {},
   "source": [
    "If you have not configured the Pytorch environment (GPU version) on your personal computer, you may not be able to run this notebook \n",
    "or it will run very slowly. \\\n",
    "In this case, you might consider using Colab, a free-to-use cloud server developed by the Google Research team. \\\n",
    "\\\n",
    "The use of Colab is very simple, very similar to the operation of jupyter notebook, you can find the tutorials in the following links:  \\\n",
    "https://www.youtube.com/watch?v=inN8seMm7UI     \\\n",
    "https://research.google.com/colaboratory/faq.html   \\\n",
    "https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c  \n",
    "\\\n",
    "I have uploaded the data and code related to travel demand forecasting in my Google drive, \\\n",
    "you can directly click the link below to run the code directly on the cloud through the Colab file I shared. \\\n",
    "There is no need to configure any environment, but you need to have a Google account.   \\\n",
    "https://drive.google.com/drive/folders/1gHIcapQ7ILvmnf8vgO0mKjN3NozgspR2?usp=sharing\n",
    "\n",
    "After opening the link above, first you should right-click on the shared folder, select \"Add shortcut to Drive\", and then click on \"My Drive\" to save the shared folder to your Google Drive. Next, you should open the Demo.ipynb file with Google Colaboratory to run the above code on the cloud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425498b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c26998198c150a5d49337a78fda498219c22346a083e2a499426c24ff75f162e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
